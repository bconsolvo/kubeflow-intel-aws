data_dir: ./data/openwebtext

model_config:
  block_size: 1024
  n_layer: 12
  n_head: 12
  n_embd: 768
  dropout: 0.0
  bias: False
  vocab_size: null
  
optimizer_config:
  learning_rate: 6e-4
  weight_decay: 1e-1
  beta1: 0.9
  beta2: 0.95

trainer_config:
  backend: gloo
  device: cpu
  mixed_precision: bf16 # fp32 or bf16.
  compile: False
  eval_interval: 4
  log_interval: 1
  eval_iters: 4
  eval_only: False
  wandb_log: False
  batch_size: 32
  max_iters: 20
  snapshot_path: snapshot.pt
  gradient_accumulation_steps: 2 # 1x8 (num_nodes x step)
  grad_clip: 1.0
  decay_lr: True
  warmup_iters: 2
  lr_decay_iters: 20
  max_lr: 6e-4
  min_lr: 6e-5